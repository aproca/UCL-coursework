{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1: 2-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports data\n",
    "file = open('zipcombo.dat','r')\n",
    "tempdata = file.read().split('\\n')\n",
    "del tempdata[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates X and y from the data\n",
    "X = np.zeros((len(tempdata), 256))\n",
    "y = np.zeros((len(tempdata)))\n",
    "for i in range(0, len(tempdata)):\n",
    "    individ = tempdata[i].split(\" \")\n",
    "    del individ[-1]\n",
    "    X[i] = np.array(individ[1:]).astype(np.float)\n",
    "    y[i] = np.array(individ[0]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms y to one hot vectors\n",
    "def onehot(y):\n",
    "    onehoty = np.zeros((10, len(y)))\n",
    "    for i in range(0, len(y)):\n",
    "        onehoty[int(y[i])][i] = 1\n",
    "    return onehoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds an additional dimension of 1's to X to act as a bias\n",
    "def biasx(X):\n",
    "    ones = np.ones((len(X), 1))\n",
    "    Xb = np.c_[X, ones]\n",
    "    Xb = Xb.reshape(len(X), 257)\n",
    "    return Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs data transformations\n",
    "def fixdata(X, y):\n",
    "    bX = biasx(X)\n",
    "    ohy = onehot(y)\n",
    "    return bX, ohy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into 80% train and 20% test\n",
    "def train_test_split(X,y):\n",
    "    randsamp = np.random.rand(X.shape[0])\n",
    "    split = randsamp < np.percentile(randsamp, 80)\n",
    "    X_train = X[split].astype(np.float)\n",
    "    y_train = y[split].astype(np.float) \n",
    "    X_test =  X[~split].astype(np.float) \n",
    "    y_test = y[~split].astype(np.float)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into 5-folds for cross-validation\n",
    "def five_fold_split(X):\n",
    "    s = int(len(X)/5)\n",
    "    ind = np.arange(len(X)).astype(int)\n",
    "    train_index = np.zeros((5, len(X)-s))\n",
    "    test_index = np.zeros((5, s))\n",
    "    for i in range(0, 5):\n",
    "        test_index[i] = ind[0+i*s:0+(i+1)*s]\n",
    "        train_index[i] = np.delete(ind, test_index[i])        \n",
    "    return train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates table of values\n",
    "def df_generator(amean, astd, bmean, bstd, indexlabels, columnlabels, shape):\n",
    "    str1 = np.char.add(np.char.mod('%.5f', amean), \"+-\")\n",
    "    str1 = np.char.add(str1,np.char.mod('%.5f', astd))\n",
    "    str2 = np.char.add(np.char.mod('%.5f', bmean), \"+-\")\n",
    "    str2 = np.char.add(str2,np.char.mod('%.5f', bstd))\n",
    "    df = pd.DataFrame(data = np.array([str1,str2]).reshape(shape), index = indexlabels, columns = columnlabels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates table of values\n",
    "def df_generator2(amean, astd, bmean, bstd, indexlabels, columnlabels, shape):\n",
    "    str1 = np.char.add(np.char.mod('%.5f', amean), \"+-\")\n",
    "    str1 = np.char.add(str1,np.char.mod('%.5f', astd))\n",
    "    str2 = np.char.add(np.char.mod('%.5f', bmean), \"+-\")\n",
    "    str2 = np.char.add(str2,np.char.mod('%.5f', bstd))\n",
    "    df = pd.DataFrame(data=np.array([str1,str2]).T, index = indexlabels, columns = columnlabels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes error\n",
    "def error_calculator(prediction, label): \n",
    "    mistakes = prediction[np.where(prediction != label)]\n",
    "    error = len(mistakes)/len(label)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes sigmoid function\n",
    "def sigmoid(x):\n",
    "    sig = 1/(1+np.exp(-x))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes softmax function\n",
    "def softmax(x):\n",
    "    soft = np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "    return soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes derivative of sigmoid function\n",
    "def dsigmoid(x):\n",
    "    f = 1/(1+np.exp(-x))\n",
    "    f = f*(1-f)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes gradient\n",
    "def gradient(act1, yhat, y, W2, W1, fc1, X):\n",
    "    dW2 = (1/len(y[1]))*(yhat-y)@act1.T\n",
    "    dW1 = (1/len(y[1]))*(W2.T@(yhat-y)*dsigmoid(fc1))@X\n",
    "    return dW2, dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes forward step\n",
    "def forward(W1, W2, X):\n",
    "    fc1 = W1@X.T\n",
    "    act1 = sigmoid(fc1)\n",
    "    fc2 = W2@act1\n",
    "    yhat = softmax(fc2)\n",
    "    return fc1, act1, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates weights\n",
    "def backward(W1, W2, dW1, dW2, learning_rate):\n",
    "    W2 = W2-learning_rate*dW2\n",
    "    W1 = W1-learning_rate*dW1\n",
    "    return W2, W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains neural network\n",
    "def train(X_train, y_train, epoch, hidden_size, learning_rate):\n",
    "    W1 = np.random.randn(hidden_size, len(X_train[1]))\n",
    "    W2 = np.random.randn(10, hidden_size)\n",
    "    for e in range(0, epoch):\n",
    "        fc1, act1, yhat = forward(W1, W2, X_train)      \n",
    "        dW2, dW1 = gradient(act1, yhat, y_train, W2, W1, fc1, X_train)\n",
    "        W2, W1 = backward(W1, W2, dW1, dW2, learning_rate)     \n",
    "    error = test(X_train, y_train, W1, W2, hidden_size)\n",
    "    return W1, W2, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests neural network\n",
    "def test(Xtest, ytest, W1, W2, hidden_size):\n",
    "    fc1, act1, yhat = forward(W1, W2, Xtest)\n",
    "    prediction = np.argmax(yhat, axis = 0)\n",
    "    label = np.argmax(ytest, axis = 0)\n",
    "    error = error_calculator(prediction, label)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs training and testing for specified number of runs\n",
    "def train_test(X, y, runs, epoch, hidden_size, learning_rate):\n",
    "    Etrain = np.zeros((runs))\n",
    "    Etest = np.zeros((runs))\n",
    "    for e in range(0, runs):\n",
    "        X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "        bX_train, ohy_train = fixdata(X_train, y_train)\n",
    "        bX_test, ohy_test = fixdata(X_test, y_test)\n",
    "        W1, W2, Etrain[e] = train(bX_train, ohy_train, epoch, hidden_size, learning_rate)\n",
    "        Etest[e] = test(bX_test, ohy_test, W1, W2, hidden_size)\n",
    "    return np.mean(Etrain), np.std(Etrain), np.mean(Etest), np.std(Etest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes=[240, 220, 200, 180, 160, 140, 120]\n",
    "Etrain = np.zeros((7))\n",
    "stdtrain = np.zeros((7))\n",
    "Etest = np.zeros((7))\n",
    "stdtest = np.zeros((7))\n",
    "for h in range(len(hidden_sizes)):\n",
    "    Etrain[h], stdtrain[h], Etest[h], stdtest[h] = train_test(X, y, 20, 2000, hidden_sizes[h], 1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Train Error</th>        <th class=\"col_heading level0 col1\" >Test Error</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row0\" class=\"row_heading level0 row0\" >H=240</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row0_col0\" class=\"data row0 col0\" >0.00022+-0.00011</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row0_col1\" class=\"data row0 col1\" >0.08704+-0.00620</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row1\" class=\"row_heading level0 row1\" >H=220</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row1_col0\" class=\"data row1 col0\" >0.00030+-0.00016</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row1_col1\" class=\"data row1 col1\" >0.08849+-0.00576</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row2\" class=\"row_heading level0 row2\" >H=200</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row2_col0\" class=\"data row2 col0\" >0.00040+-0.00019</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row2_col1\" class=\"data row2 col1\" >0.08750+-0.00532</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row3\" class=\"row_heading level0 row3\" >H=180</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row3_col0\" class=\"data row3 col0\" >0.00050+-0.00022</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row3_col1\" class=\"data row3 col1\" >0.08505+-0.00540</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row4\" class=\"row_heading level0 row4\" >H=160</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row4_col0\" class=\"data row4 col0\" >0.00067+-0.00027</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row4_col1\" class=\"data row4 col1\" >0.08341+-0.00581</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row5\" class=\"row_heading level0 row5\" >H=140</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row5_col0\" class=\"data row5 col0\" >0.00127+-0.00046</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row5_col1\" class=\"data row5 col1\" >0.08446+-0.00565</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559level0_row6\" class=\"row_heading level0 row6\" >H=120</th>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row6_col0\" class=\"data row6 col0\" >0.00220+-0.00048</td>\n",
       "                        <td id=\"T_27cd45d2_4cc8_11eb_87d2_4c32758ef559row6_col1\" class=\"data row6 col1\" >0.08430+-0.00468</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x114e9cc90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_generator2(Etrain, stdtrain, Etest, stdtest, \n",
    "                  [\"H=240\", \"H=220\", \"H=200\", \"H=180\", \"H=160\", \"H=140\", \"H=120\"],\n",
    "                  [\"Train Error\", \"Test Error\"], (7, 2))\n",
    "df1.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs 5-fold cross validation\n",
    "def cross_validation(X_train, y_train, epoch, hidden_sizes, learning_rate):\n",
    "    train_in, test_in = five_fold_split(X_train)\n",
    "    minE = 1000\n",
    "    besths = 1\n",
    "    for h in range(len(hidden_sizes)):\n",
    "        for i in range(0, 5):\n",
    "            train_index = train_in[i].astype(int)\n",
    "            test_index = test_in[i].astype(int)\n",
    "            X_trainfold = X_train[train_index[0]:train_index[len(train_index)-1]]\n",
    "            y_trainfold = y_train[train_index[0]:train_index[len(train_index)-1]]\n",
    "            bX_train, ohy_train = fixdata(X_trainfold,y_trainfold)\n",
    "            W1,W2,_ = train(bX_train, ohy_train, epoch, hidden_sizes[h], learning_rate)\n",
    "            X_testfold = X_train[test_index[0]:test_index[len(test_index)-1]]\n",
    "            y_testfold = y_train[test_index[0]:test_index[len(test_index)-1]]\n",
    "            bX_test, ohy_test = fixdata(X_testfold, y_testfold)\n",
    "            foldE = test(bX_test, ohy_test, W1, W2, hidden_sizes[h])\n",
    "        if foldE < minE:\n",
    "            besths = hidden_sizes[h]\n",
    "            minE = foldE\n",
    "    return besths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs cross validation on train data and uses optimal parameter h* to train\n",
    "# and test full dataset\n",
    "def cross_train_test(X, y, runs, epoch, hidden_sizes, learning_rate):\n",
    "    Etest = np.zeros((runs))\n",
    "    hsstar = np.zeros((runs))\n",
    "    for e in range(0, runs):\n",
    "        X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "        besths = cross_validation(X_train, y_train, epoch, hidden_sizes, learning_rate)  \n",
    "        bX_train, ohy_train = fixdata(X_train, y_train)\n",
    "        bX_test, ohy_test = fixdata(X_test, y_test)\n",
    "        W1, W2, _ = train(bX_train, ohy_train, epoch, besths, learning_rate)\n",
    "        Etest[e] = test(bX_test, ohy_test, W1, W2, besths)\n",
    "        hsstar[e] = besths\n",
    "        print(\"H* = \", besths)\n",
    "        print(\"Test error: \", np.mean(Etest[e]), \"+-\", np.std(Etest[e]))\n",
    "        \n",
    "    return Etest, hsstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "E, besths = cross_train_test(X, y, 20, 2000, hidden_sizes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_906daae0_4e72_11eb_87d2_4c32758ef559\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Mean hs*</th>        <th class=\"col_heading level0 col1\" >Mean Test Error</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_906daae0_4e72_11eb_87d2_4c32758ef559level0_row0\" class=\"row_heading level0 row0\" ></th>\n",
       "                        <td id=\"T_906daae0_4e72_11eb_87d2_4c32758ef559row0_col0\" class=\"data row0 col0\" >235.00000+-10.72381</td>\n",
       "                        <td id=\"T_906daae0_4e72_11eb_87d2_4c32758ef559row0_col1\" class=\"data row0 col1\" >0.09065+-0.00618</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a2c3b81d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_generator(np.mean(besths), np.std(besths), np.mean(E), np.std(E), [\"\"], \n",
    "                   [\"Mean hs*\", \"Mean Test Error\"], (1, 2))\n",
    "df2.style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
