{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 2: One-Versus-One (OVO) Soft-margin Gaussian Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QPfqIU-UKnlV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import cvxopt\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1609783154692,
     "user": {
      "displayName": "Alexandra Proca",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgrvRqHNAIOWBCdRnfCNl0ZduD0XWps5ii4l6OLA=s64",
      "userId": "13948843156994605009"
     },
     "user_tz": 0
    },
    "id": "I0EbBOOvKnlW"
   },
   "outputs": [],
   "source": [
    "# Imports data\n",
    "file = open('zipcombo.dat','r')\n",
    "tempdata = file.read().split('\\n')\n",
    "del tempdata[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1448,
     "status": "ok",
     "timestamp": 1609783161006,
     "user": {
      "displayName": "Alexandra Proca",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgrvRqHNAIOWBCdRnfCNl0ZduD0XWps5ii4l6OLA=s64",
      "userId": "13948843156994605009"
     },
     "user_tz": 0
    },
    "id": "h78sw4MGKnlW"
   },
   "outputs": [],
   "source": [
    "# Creates X and y from the data\n",
    "X = np.zeros((len(tempdata), 256))\n",
    "y = np.zeros((len(tempdata)))\n",
    "for i in range(0,len(tempdata)):\n",
    "    individ = tempdata[i].split(\" \")\n",
    "    del individ[-1]\n",
    "    X[i] = np.array(individ[1:]).astype(np.float)\n",
    "    y[i] = np.array(individ[0]).astype(np.float)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into 80% train and 20% test\n",
    "def train_test_split(X, y):\n",
    "    randsamp = np.random.rand(X.shape[0])\n",
    "    split = randsamp < np.percentile(randsamp, 80)\n",
    "    X_train = X[split].astype(np.float)\n",
    "    y_train = y[split].astype(np.float) \n",
    "    X_test =  X[~split].astype(np.float) \n",
    "    y_test = y[~split].astype(np.float)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1609783164493,
     "user": {
      "displayName": "Alexandra Proca",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgrvRqHNAIOWBCdRnfCNl0ZduD0XWps5ii4l6OLA=s64",
      "userId": "13948843156994605009"
     },
     "user_tz": 0
    },
    "id": "WIKXCoBZKnlX"
   },
   "outputs": [],
   "source": [
    "# Splits data into 5-folds for cross-validation\n",
    "def five_fold_split(X):\n",
    "    s = int(len(X)/5)\n",
    "    ind = np.arange(len(X)).astype(int)\n",
    "    train_index = np.zeros((5, len(X)-s))\n",
    "    test_index = np.zeros((5, s))\n",
    "    for i in range(0, 5):\n",
    "        test_index[i] = ind[0+i*s:0+(i+1)*s]\n",
    "        train_index[i] = np.delete(ind, test_index[i].astype(int))        \n",
    "    return train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1609783165585,
     "user": {
      "displayName": "Alexandra Proca",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgrvRqHNAIOWBCdRnfCNl0ZduD0XWps5ii4l6OLA=s64",
      "userId": "13948843156994605009"
     },
     "user_tz": 0
    },
    "id": "GL9D_vJOKnlX"
   },
   "outputs": [],
   "source": [
    "# Generates table of values\n",
    "def df_generator(amean, astd, bmean, bstd, cmean, cstd, indexlabels, columnlabels, shape):\n",
    "    str1 = np.char.add(np.char.mod('%.5f', amean), \"+-\")\n",
    "    str1 = np.char.add(str1, np.char.mod('%.5f', astd))\n",
    "    str2 = np.char.add(np.char.mod('%.5f', bmean), \"+-\")\n",
    "    str2 = np.char.add(str2, np.char.mod('%.5f', bstd))\n",
    "    str3 = np.char.add(np.char.mod('%.5f', cmean), \"+-\")\n",
    "    str3 = np.char.add(str3, np.char.mod('%.5f', cstd))\n",
    "    df = pd.DataFrame(data = np.array([str1, str2, str3]).reshape(shape), index = indexlabels, columns = columnlabels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates table of values\n",
    "def df_generator2(amean, astd, bmean, bstd, indexlabels, columnlabels, shape):\n",
    "    str1 = np.char.add(np.char.mod('%.5f', amean), \"+-\")\n",
    "    str1 = np.char.add(str1, np.char.mod('%.5f', astd))\n",
    "    str2 = np.char.add(np.char.mod('%.5f', bmean), \"+-\")\n",
    "    str2 = np.char.add(str2, np.char.mod('%.5f', bstd))\n",
    "    df = pd.DataFrame(data = np.array([str1, str2]).T, index = indexlabels, columns = columnlabels)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1609783168134,
     "user": {
      "displayName": "Alexandra Proca",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgrvRqHNAIOWBCdRnfCNl0ZduD0XWps5ii4l6OLA=s64",
      "userId": "13948843156994605009"
     },
     "user_tz": 0
    },
    "id": "RZ27wuGGKnlY"
   },
   "outputs": [],
   "source": [
    "# Computes Gaussian Kernel\n",
    "def kernel(Xi, Xt, c):\n",
    "    Xiprime = np.sum(Xi**2, axis = 1, keepdims = True)\n",
    "    Xtprime = np.sum(Xt.T**2, axis = 0, keepdims = True)\n",
    "    texp = Xiprime+Xtprime-2*np.dot(Xi, Xt.T)\n",
    "    K = np.exp(-c*texp)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1609783186349,
     "user": {
      "displayName": "Alexandra Proca",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgrvRqHNAIOWBCdRnfCNl0ZduD0XWps5ii4l6OLA=s64",
      "userId": "13948843156994605009"
     },
     "user_tz": 0
    },
    "id": "bBreq6YRKnlY"
   },
   "outputs": [],
   "source": [
    "# Uses quadratic programming (QP) to find SVM solution for one classifier\n",
    "def train_one(X_train, y_train, K, C, c):\n",
    "    N = X_train.shape[0]\n",
    "    P = matrix(np.dot(y_train, y_train.T)*K)\n",
    "    q = matrix(np.ones((N, 1))*-1)\n",
    "    A = matrix(y_train.reshape(1, -1).astype('float'))\n",
    "    bias = matrix(np.zeros(1))\n",
    "    G = matrix(np.vstack((np.eye(N)*-1, np.eye(N))))\n",
    "    h = matrix(np.hstack((np.zeros(N), np.ones(N)*C)))\n",
    "    sol = solvers.qp(P, q, G, h, A, bias)\n",
    "    lambdas = np.array(sol['x'])\n",
    "    ind = (lambdas > 0.0001).flatten()\n",
    "    sv_x = X_train[ind]\n",
    "    sv_y = y_train[ind]\n",
    "    sv_lambdas = lambdas[ind]\n",
    "    sv_kernel = kernel(sv_x, sv_x, c)\n",
    "    b = np.median(sv_y-np.sum(sv_kernel*sv_lambdas*sv_y,axis=0).reshape(-1, 1))    \n",
    "    return sv_x, sv_y, sv_lambdas, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains all (K choose 2) classifiers\n",
    "def train_all(X_train, y_train, c, C):\n",
    "    k = len(np.unique(y_train))\n",
    "    sv_x_arr = []\n",
    "    sv_y_arr = []\n",
    "    sv_lambdas_arr = []\n",
    "    b_arr = []\n",
    "    ind = 0\n",
    "    K = kernel(X_train, X_train, c)\n",
    "    for i in range(0, k):\n",
    "        for j in range(i+1, k):\n",
    "            ind = np.logical_or(y_train == i, y_train == j)\n",
    "            ind = ind.flatten()\n",
    "            ty = y_train[ind]\n",
    "            ty[ty == j] = -1\n",
    "            ty[ty == i] = 1\n",
    "            tx = X_train[ind]\n",
    "            tK = K[ind]\n",
    "            tK = tK[:, ind]\n",
    "            sv_x, sv_y, sv_lambdas, b = train_one(tx, ty, tK, C, c)\n",
    "            sv_x_arr.append(sv_x)\n",
    "            sv_y_arr.append(sv_y)\n",
    "            sv_lambdas_arr.append(sv_lambdas)\n",
    "            b_arr.append(b)\n",
    "    return sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests one classifier\n",
    "def test_one(Xtest, sv_x, sv_y, sv_lambdas, b, c):\n",
    "    K = kernel(sv_x, Xtest, c)\n",
    "    y_hat = np.sum(np.multiply(K, sv_lambdas*sv_y.reshape(-1, 1)), axis = 0).reshape(-1, 1)+b\n",
    "    y_hatsign = np.sign(y_hat)\n",
    "    y_hatsign[np.where(y_hatsign == 0)] = -1\n",
    "    return y_hatsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests using all (K choose 2) classifiers, makes final predictions, and computes error\n",
    "def test_all(X_train, y_train, X_test, y_test, d, sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr):\n",
    "    k = len(np.unique(y_test))\n",
    "    confidence = np.zeros((int(k*(k-1)/2), len(X_test)))\n",
    "    ind = 0\n",
    "    for i in range(0, k):\n",
    "        for j in range(i+1, k):\n",
    "            y_hatsign = test_one(X_test, sv_x_arr[ind], sv_y_arr[ind], sv_lambdas_arr[ind], b_arr[ind], d)\n",
    "            confidence[ind] = y_hatsign.reshape(y_hatsign.shape[0])\n",
    "            ind += 1\n",
    "    kconfidence = np.zeros((k, len(X_test)))\n",
    "    for i in range(0, k):\n",
    "        ind = 0\n",
    "        for j in range(0, k):\n",
    "            for l in range(j+1, k):\n",
    "                if i == j:\n",
    "                    kconfidence[i] += confidence[ind]\n",
    "                elif i == l:\n",
    "                    kconfidence[i] -= confidence[ind]\n",
    "                ind += 1\n",
    "    predictions = np.zeros(len(X_test))\n",
    "    for i in range(0, len(X_test)):\n",
    "        predictions[i] = np.argmax(kconfidence[:, i])\n",
    "    mistakes = len(np.where(predictions != y_test.reshape(y_test.shape[0]))[0])\n",
    "    return mistakes/len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ezYQu6EAKnlb"
   },
   "outputs": [],
   "source": [
    "# Runs training and testing for specified number of runs\n",
    "def train_test(X, y, runs, d, C):\n",
    "    Etrain = np.zeros((runs))\n",
    "    Etest = np.zeros((runs))\n",
    "    for e in range(0, runs):\n",
    "        X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "        sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr = train_all(X_train, y_train, d, C)\n",
    "        Etrain[e] = test_all(X_train, y_train, d, sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr)\n",
    "        Etest[e] = test_all(X_test, y_test, d, sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr)\n",
    "    return np.mean(Etrain), np.std(Etrain), np.mean(Etest), np.std(Etest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00901815 0.01401815 0.01901815]\n"
     ]
    }
   ],
   "source": [
    "# Parameter initialization\n",
    "median = np.median(distance.cdist(X, X))\n",
    "c = 1/median\n",
    "cS = np.arange(c-0.055, c-0.04, 0.005)\n",
    "print(cS)\n",
    "CS=[1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31DhqM-JKnlb"
   },
   "outputs": [],
   "source": [
    "Etrain = np.zeros((6))\n",
    "stdtrain = np.zeros((6))\n",
    "Etest = np.zeros((6))\n",
    "stdtest = np.zeros((6))\n",
    "ind = 0\n",
    "for i in range(len(CS)):\n",
    "    for j in range(len(cS)):\n",
    "        Etrain[ind], stdtrain[ind], Etest[ind], stdtest[ind] = train_test(X, y, 20, cS[j], CS[i])\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_af0afdca_5135_11eb_8245_4c32758ef559\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Train Error</th>        <th class=\"col_heading level0 col1\" >Test Error</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row0\" class=\"row_heading level0 row0\" >C=1,c=0.009</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row0_col0\" class=\"data row0 col0\" >0.00477+-0.00038</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row0_col1\" class=\"data row0 col1\" >0.02403+-0.00257</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row1\" class=\"row_heading level0 row1\" >C=1,c=0.014</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row1_col0\" class=\"data row1 col0\" >0.00212+-0.00028</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row1_col1\" class=\"data row1 col1\" >0.02304+-0.00382</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row2\" class=\"row_heading level0 row2\" >C=1,c=0.019</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row2_col0\" class=\"data row2 col0\" >0.00138+-0.00020</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row2_col1\" class=\"data row2 col1\" >0.02710+-0.00304</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row3\" class=\"row_heading level0 row3\" >C=10,c=0.009</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row3_col0\" class=\"data row3 col0\" >0.00017+-0.00010</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row3_col1\" class=\"data row3 col1\" >0.02242+-0.00318</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row4\" class=\"row_heading level0 row4\" >C=10,c=0.014</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row4_col0\" class=\"data row4 col0\" >0.00022+-0.00009</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row4_col1\" class=\"data row4 col1\" >0.02355+-0.00299</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row5\" class=\"row_heading level0 row5\" >C=10,c=0.019</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row5_col0\" class=\"data row5 col0\" >0.00025+-0.00005</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row5_col1\" class=\"data row5 col1\" >0.02460+-0.00293</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row6\" class=\"row_heading level0 row6\" >C=100,c=0.009</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row6_col0\" class=\"data row6 col0\" >0.00011+-0.00005</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row6_col1\" class=\"data row6 col1\" >0.02169+-0.00292</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row7\" class=\"row_heading level0 row7\" >C=100,c=0.014</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row7_col0\" class=\"data row7 col0\" >0.00012+-0.00004</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row7_col1\" class=\"data row7 col1\" >0.02250+-0.00223</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_af0afdca_5135_11eb_8245_4c32758ef559level0_row8\" class=\"row_heading level0 row8\" >C=100,c=0.019</th>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row8_col0\" class=\"data row8 col0\" >0.00009+-0.00006</td>\n",
       "                        <td id=\"T_af0afdca_5135_11eb_8245_4c32758ef559row8_col1\" class=\"data row8 col1\" >0.02430+-0.00304</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14fd0bf10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_generator2(Etrain, stdtrain, Etest, stdtest, [\"C=1,c=0.009\", \"C=1,c=0.014\", \n",
    "                                                      \"C=1,c=0.019\",\"C=10,c=0.009\", \"C=10,c=0.014\", \"C=10,c=0.019\", \"C=100,c=0.009\", \"C=100,c=0.014\", \"C=100,c=0.019\"], \n",
    "                   [\"Train Error\",\"Test Error\"], (9, 2))\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TQ1ppf7yKnlc"
   },
   "outputs": [],
   "source": [
    "# Performs 5-fold cross validation\n",
    "def cross_validation(X_train, y_train, CS, cS):\n",
    "    train_in, test_in = five_fold_split(X_train)\n",
    "    minE = 1000\n",
    "    bestc = 1\n",
    "    bestC = 1\n",
    "    for C in CS:\n",
    "        for c in cS:\n",
    "            for i in range(0, 5):\n",
    "                train_index = train_in[i].astype(int)\n",
    "                test_index = test_in[i].astype(int)\n",
    "                X_trainfold = X_train[train_index[0]:train_index[len(train_index)-1]]\n",
    "                y_trainfold = y_train[train_index[0]:train_index[len(train_index)-1]]\n",
    "                sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr = train_all(X_trainfold, y_trainfold, c, C)\n",
    "                X_testfold = X_train[test_index[0]:test_index[len(test_index)-1]]\n",
    "                y_testfold = y_train[test_index[0]:test_index[len(test_index)-1]]\n",
    "                foldE = test_all(X_testfold, y_testfold, c, sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr)\n",
    "            if foldE < minE:\n",
    "                bestC = C\n",
    "                bestc = c\n",
    "                minE = foldE\n",
    "    return bestc, bestC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Dy29jKfVKnlc"
   },
   "outputs": [],
   "source": [
    "# Performs cross validation on train data and uses optimal parameters C*, c* to train\n",
    "# and test full dataset\n",
    "def cross_train_test(X, y, runs, param):\n",
    "    Etest = np.zeros((runs))\n",
    "    cstar = np.zeros((runs))\n",
    "    for e in range(0, runs):\n",
    "        X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "        bestc, bestC = cross_validation(X_train, y_train, CS, cS)\n",
    "        sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr = train_all(X_train, y_train, bestc, bestC)\n",
    "        Etest[e] = test_all(Xtest, ytest, bestc, sv_x_arr, sv_y_arr, sv_lambdas_arr, b_arr)\n",
    "        cstar[e] = bestc  \n",
    "        Cstar[e] = bestC      \n",
    "    return Etest, cstar, Cstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUqreSwHKnld"
   },
   "outputs": [],
   "source": [
    "E, bestc, bestC = cross_train_test(X, y, 20, list(range(1, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_d1b89086_51ca_11eb_8245_4c32758ef559\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Mean C</th>        <th class=\"col_heading level0 col1\" >Mean c</th>        <th class=\"col_heading level0 col2\" >Mean Test Error</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_d1b89086_51ca_11eb_8245_4c32758ef559level0_row0\" class=\"row_heading level0 row0\" ></th>\n",
       "                        <td id=\"T_d1b89086_51ca_11eb_8245_4c32758ef559row0_col0\" class=\"data row0 col0\" >95.50000+-19.61505</td>\n",
       "                        <td id=\"T_d1b89086_51ca_11eb_8245_4c32758ef559row0_col1\" class=\"data row0 col1\" >0.00902+-0.00000</td>\n",
       "                        <td id=\"T_d1b89086_51ca_11eb_8245_4c32758ef559row0_col2\" class=\"data row0 col2\" >0.02183+-0.00346</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1047d7190>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_generator(np.mean(bestC), np.std(bestC), np.mean(bestc), np.std(bestc), np.mean(E), np.std(E), \n",
    "                   [\"\"],[\"Mean C\", \"Mean c\", \"Mean Test Error\"], (1, 3))\n",
    "df2.style                "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "0078A2P1Q7P2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
